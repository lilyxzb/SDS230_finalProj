---
title: "Final_project_sds230"
output: 
  word_document: 
    fig_height: 6
    fig_width: 9
date: "2024-07-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}

library(car)
library(TeachingDemos)
library(plyr)
library(dplyr)
library(tidyr)
library(TeachingDemos)
library(plyr)
source("https://raw.githubusercontent.com/talgalili/R-code-snippets/master/boxplot.with.outlier.label.r") # boxplot with outlier function
source("/Users/lilybroach/Desktop/YaleSDS230/regJDRS.txt")
wb <- read.csv("/Users/lilybroach/Desktop/YaleSDS230/final_proj/WB.2016.csv")
library(readxl)
```


# Introduction
....
We will introduce each subsection by describing the variables we are using in that section



## data cleaning


## descriptive plots, summary information



```{r}

```

# Analysis


## T Test



## Correlation 
We are performing a simple linear regression to model the relationship between infant mortality rate (per 1,000 live births) and measles immunization rate for infants 12 - 23 months old. The assumptions are random, normally distributed errors centered at zero with constant variance (homoskedasticity) and linearity between variables. Histograms show that Measles vaccination rates are heavily left-skewed, and infant mortality is heavily right-skewed.

```{r}
# remove NAs 
mort <- na.omit(wb %>% dplyr::select(Measles,InfMort))
hist(mort$Measles, col = "red", main = "Histogram of Measles Immunization Rate",xlab = "Measles Immunization Rate")
hist(mort$InfMort, col = "orange", main = "Histogram of Infant Mortality Rate",xlab = "Infant Mortality Rate")

# fit linear regression model
lm1 <- lm(InfMort ~ Measles, data = mort)

# correlation test
cor1 <- cor(mort$Measles,mort$InfMort)
```
 We fit an initial linear model to these variables and calculate the correlation and R-squared value.

```{r}

#plot 
plot(InfMort ~ Measles, data = mort, main = "Infant Mortality Rate vs Measles Immunization Rate", xlab = "% of Measles Immunization for 12-23 month olds", ylab = "Infant Mortality Rate per 1,000 Live Births",
     pch = 19, col = "red")
mtext(paste("r = ", round(cor1, 2) , ", rsquared = ", round(cor1^2,2),", slope = ", round(lm1$coef[2], 2)))
abline(lm1$coef, col = "blue", lwd = 3)
#look at residuals 

summary(mort$Measles)
```

There is a moderate to strong negative relationship between % Measles vaccinations and infant mortality. An R-squared of 0.31 means 31% of the variability in infant mortality rate is explained by the model. However, since measles immunization rates cluster near 100%, this causes issues with spread and variance. Residual plots can help investigate this further.

```{r}
myResPlots2(lm1)
```

There looks to be some hetereoskedasticity in the fit vs studentized residuals, likely due to the extreme right skew of measles vacciination. This makes sense, as the median measles % vaccination is 93 and the mean is 87.21; most of the data is centered on the right.  Since measles vaccination is a percentage, we can perform logit transformation and see if this improves the fit. 
```{r}
mort$logitMeasles <- logit(mort$Measles)
hist(mort$logitMeasles, col = "violet", main = "histogram of logit % Measles Immunization", xlab = "logit % Measles Immunization")
summary(mort$logitMeasles)
```
After taking logit of % Measles vaccination, we can see in the histogram is is more evenly distributed. There is still a left skew, but this is to be expected since countries still have high measles vaccination rates. With our transformed predictor, we make another scatterplot and fit a new regression model.

```{r}
# fit linear regression model
lm2 <- lm(InfMort ~ logitMeasles, data = mort)

# correlation test
cor2 <- cor(mort$logitMeasles,mort$InfMort)

```
```{r}
#plot 
plot(InfMort ~ logitMeasles, data = mort, main = "Infant Mortality Rate vs logit Measles Immunization Rate", xlab = "logit % of Measles Immunization for 12-23 month olds", ylab = "Infant Mortality Rate per 1,000 Live Births",
     pch = 19, col = "red")
mtext(paste("r = ", round(cor2, 2) ,", rsquared = ", round(cor2^2,2), ", slope = ", round(lm1$coef[2], 2)))
abline(lm2$coef, col = "blue", lwd = 3)


myResPlots2(lm2)


```
In the new scatterplot with logit measles, the data is more dispersed along the x axis. The spread and linear assumptions of correlation and linear models are better met with the transformed variable. The measles histogram is less skewed, the residual plot has less unequal variance, and the overall model fit is better with the transformed predictor variable.  Since R-squared is .28, 28% of the variability in infant mortality can be explained by this model. While this is lower than the squared value of the previous model (R-squared = .31), the current model with logit measles vaccination is a better fit since the underlying assumptions are better met. The best model fit isn't necessarily the model with the highest R-squared.

### Bootstrap CI for Correlation
In order to check the slope we calculated using parametric tests, we employ non parametric bootstrapping in order to calculate confidence intervals for the slope between logit Measles immunization rate and infant mortality rate.

```{r}
mort2 <- mort %>% dplyr::select(logitMeasles,InfMort)
N <- nrow(mort2)

#Specify how many boostrap samples to take
n_samp <- 10000

bResults <- rep(NA, n_samp)

for(i in 1:n_samp){
  #get vector of rows in our fake sample
  s <- sample(1:N, N , replace = T)
  fakeData <-  mort2[s, ]
    
  #Get bootstrapped regression slope

  bResults[i] <- lm(fakeData[, 2] ~ fakeData[, 1])$coef[2]
}

#Get percentiles for 2.5 and 97.5

ci_slope <- quantile(bResults, c(.025, .975))


#get regression results again
lm2 <- lm(InfMort ~ logitMeasles, data = mort)

#Histogram of bootstrapped regression slopes with CI's (both bootstrapped and theoretical)
hist(bResults, col = "blue", main = "Bootstrapped Slopes", xlab = "Sample Slope", breaks = 50)
abline(v = ci_slope, lwd = 3, col = "red")
abline(v = confint(lm2,'logitMeasles'), lwd = 3, col = "green", lty = 2)
legend("topleft", c("Theoretical CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2, 1))

```

The histograms above show the bootstrapped slopes. The bootstrapped confidence intervals are only a bit wider than the theoretical. This could mean that the linear model we fit approximated the assumptions of normality, homoskedasticity, and independence of errors. The bootstrapping is non parametric therefore capturing more of the true variability in the data.  We can look at normal quantile plots of the bootstrapped data to further visualize the bootstrapped distribution.

```{r}
qqPlot(bResults, main = "Normal Quantile Plot of Bootstrapped Slopes")
```
As expected, distributions for slope approximate normality. There is a slight right skew in the normal quantile plot of bootstrapped correlation which is also reflected in the histogram.The histogram for slope looks very near normal, and the data falls almost entirely along the straight line in the normal quantile plot. 

## Multiple regression

*introduction, data explanation, variables, etc*

### look at response variable Military Expenditures
```{r}
summary(wb$Military) #note: there are NA and 0 in data
boxplot(wb$Military, col = "red", main = "Military Expenditures (% of GDP)", horizontal = T, xlab = "% military expenditure")
hist(wb$Military, col = "red", main = "Military Expenditures (% of GDP)", xlab = "% military expenditure")
qqPlot(wb$Military, main = "Military Expenditures (% of GDP)", pch = 19)
```

The data is heavily right-skewed and not normally distributed. These plots suggest using a logit transformation, which helps with probabilities or percentages. Due to zeros in the data, we add a small amount to each value to avoid issues with the logit function.

```{r}
#sort(wb$military)
#wb$logitMilitary <- logit(wb$Military + .002)
#wb$logitMilitary <- logit(wb$Military + .02)
wb$logitMilitary <- logit(wb$Military + .2) # since there are zeros in the data

hist(wb$logitMilitary, col = "pink", main = "Histogram of logit Military Expenditures % of GFP")
qqPlot(wb$logitMilitary, pch = 19)

```

Now the data is more normally distributed. There are a  few potential outliers, spending more or less than expected on military. The box plot below shows these countries.

```{r, fig.height=6}
boxplot.with.outlier.label(wb$logitMilitary, wb$Country, col = "red", ylab = "logit military expenditure",ylim = c(-7,-1),
 main = "Boxplot of Logit Military Expenditure")
```

In this box plot, Haiti, Somalia, Panama, Iceland, and Costa Rica all have approximately 0% military expenditure. Oman and Saudi Arabia have relatively higher military expenditure compared to other countries in the 2016 World Bank dataset.

*Now that our response variable is transformed, we can begin to look at the relationships with this transformed variable and some potential explanatory variables. First, we make correlation plot of all the possible predictors we want to include in our model*
```{r}

```



## 2-Way ANOVA

### Introduction
We are interested in predicting life expectancy based on some categorical variables a data set concerning global abortion laws concerning self-managed abortion. More information can be found [here](https://legacy.lawatlas.org/datasets/global-medication-abortion-laws). We want to understand how allowing abortions in abortion designated health facilities ('healthfacility') and penalizing individuals seeking abortions ('penalpreg') affects life expectancy. We clean the Global Medication Data (GMA) by converting non 1 and 0 values to NA and recoding 1 as Yes and 0 as No. Then, we join the GMA and World bank dataset by country, and remove rows with NAs. The resulting dataframe has 143 unique countries. We begin the analysis using boxplots to examine the life expectancy distributions for each level of 'healthfacility' and 'penalpreg'. The variance and life expectancy differences across groups are minimal.

```{r}
GMA <- read_xlsx("/Users/lilybroach/Desktop/YaleSDS230/final_proj/GMA_data.xlsx")
str(GMA)

for (i in 4:ncol(GMA)) {
  GMA[[i]] <- gsub("[.]",NA,GMA[[i]])
  GMA[[i]] <- gsub("1","Yes",GMA[[i]])
  GMA[[i]] <- gsub("0", "No", GMA[[i]])
}

# join datasets so by by Country and Jurisdiction name 
wbGMA <- left_join(wb, GMA, join_by(Country == Jurisdictions))

wbGMA$healthfacility <- wbGMA$`glob_placea_Health facility specifically designated to provide abortions`
wbGMA$penalpreg <- wbGMA$`glob_penaltPregnant person`


wbGMA2 <- na.omit(wbGMA[,c('penalpreg','healthfacility','LifeExp','Country','Fertility16')])
head(wbGMA2)
length(unique(wbGMA2$Country))

boxplot(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility, xlab = "Penalty for Pregnant Individual : Legal in Healthcare Facility", ylab = "Life Expectancy", col = "blue")
mtext("Distribution of Life Expectancy by", line = 1)
mtext("Abortion Legality in Health Facility and Penalization")
```

Now we want to check interactions between the categorical variables and continuous variable. It is also important to note that we have a small sample size and an unbalanced design as seen in the table below, the number of observations in each group is not the same.

```{r}
interaction.plot(wbGMA2$healthfacility,wbGMA2$penalpreg, wbGMA2$LifeExp, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot",)
mtext("Between Penalty for Pregnant Individual & Legal in Healthcare Facility")

table(wbGMA2$penalpreg,wbGMA2$healthfacility)

```

The lines are not parallel, suggesting a potential interaction effect between penalizing a pregnant woman for abortion ('penalpreg') and allowing abortions in designated health facilities ('healthfacility'). For penalized women, countries permitting abortions in health facilities have a slightly higher mean life expectancy. Conversely, for non-penalized women, countries not permitting abortions in  health facilities have a higher mean life expectancy. However, this plot is not a statistical test.

We ran a two-way ANOVA with 'penalpreg,' 'healthfacility,' and their interaction. None were significant. A second ANOVA without the interaction showed a significant main effect of 'healthfacility.' Abortions in government health facilities significantly affect life expectancy. A linear model without the interaction had a P value of 0.015, lower than the model with the interaction (P = 0.03), indicating a better fit. However, the adjusted R-squared is 0.04, explaining only 4% of the variance in life expectancy. The model may not explain the data well due to the small sample size and only one significant effect.

```{r}

aov1 <- aov(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility + wbGMA2$penalpreg*wbGMA2$healthfacility)
Anova(aov1, type = 'III')
#taking out insig interaction

#additive model
aov2 <- aov(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility)
Anova(aov2, type = 'III')

lm1 <- lm(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility + wbGMA2$penalpreg*wbGMA2$healthfacility)
summary(lm1)

lm2 <- lm(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility)
summary(lm2)


```

Plotting fit vs. studentized residuals shows that the residuals are approximately normally distributed with no major violations of equal variances. However, some non-conforming data in the right tail likely result from life expectancy being left-skewed, with a maximum of about 84 years. In a normal distribution, the maximum value would be higher, balancing the upper right tail.

```{r}
summary(wbGMA2$LifeExp)
myResPlots2(aov1)

```


```{r}

```


## conclusion and summary
