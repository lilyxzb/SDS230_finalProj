---
title: "Final_project_sds230"
output: word_document
date: "2024-07-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(TeachingDemos)
library(plyr)
library(dplyr)
library(tidyr)
library(TeachingDemos)
library(plyr)
source("https://raw.githubusercontent.com/talgalili/R-code-snippets/master/boxplot.with.outlier.label.r") # boxplot with outlier function
source("/Users/lilybroach/Desktop/YaleSDS230/regJDRS.txt")
wb <- read.csv("/Users/lilybroach/Desktop/YaleSDS230/final_proj/WB.2016.csv")

```

# Introduction

## data explanation

## data cleaning


## descriptive plots, summary information



```{r}

```

# Analysis


## T Test



## Correlation 
*discuss assumptinos of correlation and linear regressin, which i believe is a GLM so need to talk ab..out that too* 
Linear regression is a type of generalized linear model used to .. the assumptions of GLM is that we have random, normally distributed errors centered at zero with constant variance. There should be homoskedasticity, with constant variance across groups. In addition, for simple linear regression, the variables must be linearly related.
*Introduction to quesiton we are investigation. try logit to measles immunization, may need to subtract when taking logit, correlated to infant mortality?*
First, we want to investigate whether there is a relationship between infant mortality and measles vaccination rates. We check the distribution of the variables and see that Measles vaccination rates are heavily left skewed and infant mortality is heavily right skewed. We fit an inital linear model to these variables and calculate correlation and rsquared value.
```{r}
# remove NAs 
mort <- na.omit(wb %>% dplyr::select(Measles,InfMort))
hist(mort$Measles)
hist(mort$InfMort)

# fit linear regression model
lm1 <- lm(InfMort ~ Measles, data = mort)

# correlation test
cor1 <- cor(mort$Measles,mort$InfMort)


#plot 
plot(InfMort ~ Measles, data = mort, main = "Infant Mortality Rate vs Measles Immunization Rate", xlab = "% of Measles Immunization for 12-23 month olds", ylab = "Infant Mortality Rate per 1,000 Live Births",
     pch = 19, col = "red")
mtext(paste("r = ", round(cor1, 2) , ", rsquared = ", round(cor1^2,2),", slope = ", round(lm1$coef[2], 2)))
abline(lm1$coef, col = "blue", lwd = 3)
#look at residuals 

summary(mort$Measles)
```
There is a moderate - strong negative relationship between % Measles immunizations and infant mortality, and the rsquared of .31 represents that 31% of the variability in infant mortality rate can be explained by this model. However, since measles immunization is piled towards 100%, this casues probelms of spread and variance. We can look at the residual plots to investiagte this issue further.

```{r}
myResPlots2(lm1)
```

There looks to be some hetereoskedasticity in the fit vs studentized residuals, likely due to the extreme right skew of measles vacciination. This makes sense, as the median measles % vaccination is 93 and the mean is 87.21; most of the data is centered on the right.  Since measles vaccination is a percentage, we can perform logit transformation and see if this improves the fit. 
```{r}
mort$logitMeasles <- logit(mort$Measles)
hist(mort$logitMeasles)
summary(mort$logitMeasles)
```
After taking logit of % Measles vaccination, we can see in the histogram is is more evenly distributed. There is still a left skew, but this is to be expected since countries still have high measles vaccination rates. With our transformed predictor, we make another scatterplot and fit a new regression model.


```{r}
# fit linear regression model
lm2 <- lm(InfMort ~ logitMeasles, data = mort)

# correlation test
cor2 <- cor(mort$logitMeasles,mort$InfMort)


#plot 
plot(InfMort ~ logitMeasles, data = mort, main = "Infant Mortality Rate vs logit Measles Immunization Rate", xlab = "logit % of Measles Immunization for 12-23 month olds", ylab = "Infant Mortality Rate per 1,000 Live Births",
     pch = 19, col = "red")
mtext(paste("r = ", round(cor2, 2) ,", rsquared = ", round(cor2^2,2), ", slope = ", round(lm1$coef[2], 2)))
abline(lm2$coef, col = "blue", lwd = 3)


myResPlots2(lm2)


```
*In the new scatterplot with logit measles, the data is more dispersed along the x axis. The spread and linear assumptions of correlation and linear models are better met with the transformed variable. The measles histogram is less skewed, the residual plot has less unequal variance, and the overall model fit is better with the transformed predictor variable.  With an rsquared value of .28, 28% of the variability in infant mortality can be explained by this model. While this is lower than the squared value of the previous model (rsquared = .31), the current model with logit measles vaccination is a better fit since the underlying assumptions are better met. The rsquared value is only one way of interpreting good model fit, and we don't always necessarily want the model with the highest rsquared.*


*do bootstrapping as comparison to parametric function*
### Bootstrap CI for Correlation and Slope

```{r}
mort2 <- mort %>% dplyr::select(logitMeasles,InfMort)
N <- nrow(mort2)

#Specify how many boostrap samples to take
n_samp <- 10000

corResults <- rep(NA, n_samp)
bResults <- rep(NA, n_samp) 

for(i in 1:n_samp){
  #get vector of rows in our fake sample
  s <- sample(1:N, N , replace = T)
  fakeData <-  mort2[s, ]
    
  #Get bootstrapped correlation and regression slope
  corResults[i] <- cor(fakeData[, 1], fakeData[, 2])
  bResults[i] <- lm(fakeData[, 2] ~ fakeData[, 1])$coef[2]

}

#Get percentiles for 2.5 and 97.5
ci_r <- quantile(corResults, c(.025, .975))
ci_slope <- quantile(bResults, c(.025, .975))

#Histogram of bootstrapped correlation values with CI's (both bootstrapped and theoretical)
hist(corResults, col = "blue", main = "Bootstrapped Correlations", xlab = "Sample Correlation", breaks = 50)
abline(v = ci_r, lwd = 3, col = "red")
abline(v = cor.test(mort2$logitMeasles, mort2$InfMort)$conf.int, lwd = 3, col = "green", lty = 2)
legend(-.4, 350, c("Theoretical CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2, 1))


#get regression results again
lm2 <- lm(InfMort ~ logitMeasles, data = mort)

#Histogram of bootstrapped regression slopes with CI's (both bootstrapped and theoretical)
hist(bResults, col = "blue", main = "Bootstrapped Slopes", xlab = "Sample Slope", breaks = 50)
abline(v = ci_slope, lwd = 3, col = "red")
abline(v = confint(lm2,'logitMeasles'), lwd = 3, col = "green", lty = 2)
legend("topleft", c("Theoretical CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2, 1))

#reminder of regression results
summary(lm1)


```
The histograms above show the bootstrapped data both correlation and slope, the bootstrapped confidence intervals are a bit wider than the theoretical. In both cases, the bootstrapped confidence intervals are more conservative than the theoretical, which makes sense because the bootstrapping is non parametric therefore capturing more of the true variability in the data. We can look at normal quantile plots of the bootstrapped data to further visualize the distribution.

```{r}
qqPlot(corResults, main = "Normal Quantile Plot of Bootstrapped Correlation")
qqPlot(bResults, main = "Normal Quantile Plot of Bootstrapped Slopes")
```
As expected, distributions for correlation and slope approximate reflect normality. There is a slight right skew in the normal quantile plot of bootstrapped correlation which is also reflected in the histogram.  The histogram for slope looks very near normal, and the data falls almost entirely along the straight line in the normal quantile plot. 


## Multiple regression


### Multiple Regression
#### look at response variable Military Expenditures
```{r}
summary(wb$Military) #note: there are NA and 0 in data
boxplot(wb$Military, col = "red", main = "Military Expenditures (% of GDP)", horizontal = T, xlab = "% military expenditure")
hist(wb$Military, col = "red", main = "Military Expenditures (% of GDP)", xlab = "% military expenditure")
qqPlot(wb$Military, main = "Military Expenditures (% of GDP)", pch = 19)
```
*The data is heavily right skewed and not normally distributed. These plots all suggest we might want to look at things on the logit because its %. logit function is log(p/(1-p)) or it is log(%/(100-%))*

```{r}


wb$logitMilitary <- logit(wb$Military + .2) # since there are zeros in the data
sort(wb$logitMilitary)
summary(wb$logitMilitary)
hist(wb$logitMilitary)
qqPlot(wb$logitMilitary, pch = 19)
boxplot(wb$logitMilitary, col = "red", main = "Logit Military Expenditures % of GDP", ylab = "logit military expenditure")


```
*Now the data seems more reasonably normally distributed and we begin to look at the predictor variables. We notice that there are a few potential outliers spending more and less than what we might expect from a normal distribution. We can see the countries that these outliers belong to below.*

```{r, fig.height=6}
boxplot.with.outlier.label(wb$logitMilitary, wb$Country, col = "red", ylab = "logit military expenditure",ylim = c(-7,-1),
 main = "Boxplot of Logit Military Expenditure")
```
In this boxplot, Haiti, Somalia, Panama, ICeland and Costa Rica all have approximately zero % military expenditure, so they are pointing to the same value. Oman and Saudi Arabia have realtively higher % military expenditure than the other countries listed in the world bank 2016 dataset.

*Now that our response variable is transformed, we can begin to look at the relationships with this transformed variable and some potential explanatory variables. First, we make correlation plot of all the possible predictors we want to include in our model*
```{r}

```



## 2-Way ANOVA

### Introduction
We are interested in predicting life expectancy based on some categorical variables a data set concerning global abortion laws concerning self-managed abortion. *need to talk about what variables we are using from GWB dataset.* Life expectancy is a variable from the world bank dataset that is slightyl left skewed. However, this should not be a problem if the residuals are normally distirbuted and show homoskedasticity after fitting a model. 


First, read in data, do some data cleaning by converting non 1 and 0 to NA, converting 1 to Yes and 0 to No. Then, we can join the GMA dataset by country name with the world bank dataset. The names in the GMA dataset are long, so we assign new names to them. THe indicator variable for pregnant women being penalized for participating in an unlawful abortion becomes "penalpreg" and the indicator variable indicating whether an abortion is legally premitted to take place in a government health facility becomes healthfacility. Additionally, in order to make sure the two way ANOVA is a balanced design, we removed rows with NAs in our columns of interest from the dataframe. In the end, to perform two way ANOVA, we have 143 unique countries with information from the world bank and GMA data set. In order to get a sense of the data, we can use boxplots to look at the distribution of life expectancy for each level of the two categorical variables. The variance between groups doesn't seem hugely different, and there also doesn't seem to be a real difference in life expectancy across the groups. 
```{r}
GMA <- read_xlsx("/Users/lilybroach/Desktop/YaleSDS230/final_proj/GMA_data.xlsx")
str(GMA)
for (i in 4:ncol(GMA)) {
  GMA[[i]] <- gsub("[.]",NA,GMA[[i]])
  GMA[[i]] <- gsub("1","Yes",GMA[[i]])
  GMA[[i]] <- gsub("0", "No", GMA[[i]])
}

# join datasets so by by Country and Jurisdiction name 
wbGMA <- left_join(wb, GMA, join_by(Country == Jurisdictions))

wbGMA$healthfacility <- wbGMA$`glob_placea_Government health facility`
wbGMA$penalpreg <- wbGMA$`glob_penaltPregnant person`


wbGMA2 <- na.omit(wbGMA[,c('penalpreg','healthfacility','LifeExp','Country','Fertility16')])
head(wbGMA2)
length(unique(wbGMA2$Country))

hist(wbGMA2$LifeExp, main = "Histogram of Life Expectancy",xlab = "Life Expectancy (years)", col = "purple")
#hist(log(wbGMA2$LifeExp)) still looks left skewed, almost looks worse

boxplot(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility, xlab = "Penalty for Pregnant Individual : Legal in Healthcare Facility", ylab = "Life Expectancy", col = "blue")
mtext("Distribution of Life Expectancy by", line = 1)
mtext("Abortion Legality and Penalization")
```

Now we want to check interactions between the categorical variables and continuous variable

```{r}
interaction.plot(wbGMA2$penalpreg, wbGMA2$healthfacility, wbGMA2$LifeExp, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot",)


```
The lines do not move in a parallel fashion, so there might be a significant interaction effect between whether a pregnant woman is penalized for having an abortion and whether an abortion is legally allowed to take place in a government health facility. For instances where the woman is penalized, countries permitting abortions in health facilities  have a slightly higher mean life expectancy. In instances where the pregnant woman is not penalized, countries that do not permit abortions in health facilities look like they have a higher mean life expectancy. The plot itself however is not a statistical test and is merely a suggestion for what we may see when performing the statistical test.

```{r}
aov1 <- aov(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility + wbGMA2$penalpreg*wbGMA2$healthfacility)
summary(aov1)

lm1 <- lm(wbGMA2$LifeExp ~ wbGMA2$penalpreg + wbGMA2$healthfacility + wbGMA2$penalpreg*wbGMA2$healthfacility - 1)
summary(lm1)



```
there is not a significant difference in life expectancy between groups, but the individual predictors are significant predictors of life expectancy. This could also be due to the fact that there are not very many observations (N = 143). The rsquared value could be too high due to over fitting the model, since again there are not many observations. Since there is a small sample size, the model may suit this data very well but may not be applicable if we were to introduce more new data. 


Plotting fit vs studentized residuals shows that the residuals are approximately normally distributed and there isn't a great violation in equal variances. However, there are some non conforming data on the right tail of the distribution. This is likely due to the fact that life expectancy is left skewed, with a maximum of about 84 years. In a normal distribution, we may expect the maximum life expectancy value to be higher to even out the upper right tail. 

```{r}
summary(wbGMA2$LifeExp)
myResPlots2(aov1)

```


```{r}

```


## conclusion and summary
